---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

<font color="red">editing still in progress. Following is a template:</font>

I am the Research Fellow in National University of Singapore (NUS), supervised by Prof. [Li Haizhou]([https://colips.org/~eleliha/](https://scholar.google.com/citations?user=z8_x7C8AAAAJ&hl=en)). Prior to that, I received the PhD and Master Degree from NUS in 2023 and 2019, Bachelor Degree from Soochow University in 2018.

My research interest Audio-visual speech processing, includes (audio-only or audio-visual) speaker recognition, speaker diarization, speech extraction, active speaker detection, self-supervised learning. I have published more than 10 papers at the top international AI conferences and journals such as NeurIPS, TASLP, ICASSP, INTERSPEECH. <a href='https://scholar.google.com/citations?hl=en&user=1W24GsQAAAAJ'><img src="https://img.shields.io/endpoint?url=https%3A%2F%2Fscholar.google.com%2Fcitations%3Fhl%3Den%26user%3D1W24GsQAAAAJ&logo=Google%20Scholar&labelColor=f6f6f6&color=9cf&style=flat&label=citations"></a>

# üìú Research Area
Speech Processing: Speaker recognition, speaker diarization, target speaker extraction, anti-spoofing, speech separation, voice conversion, text-to-speech

Computer Vision: Face recognition; face detection; lip reading

Multi-modal Processing: Audio-visual active speaker detection, AV speaker recognition, AV target speaker extraction, talking face generation

Algoirthm: Self-supervised speech processing

# üè´ Education

- *2021.01 - 2023.12*, Ph.D. in Speech Processing, National University of Singapore (NUS), Singapore.
- *2018.07 - 2019.06*, M.Sc. in Electronic and Computer Engineer, National University of Singapore (NUS), Singapore.

# Working Experience
- *2020.09 - Now*, Senior Research Engineer, Agency for Science, Technology and Research (A*STAR), Singapore.

# üìù Publication

**2024**
- **Tianchi Liu**, Lin Zhang, Rohan Kumar Das, Yi Ma, Ruijie Tao, Haizhou Li, *How Do Neural Spoofing Countermeasures Detect Partially Spoofed Audio?*, **INTERSPEECH (oral)**, 2024. üîó[[arXiv]](https://arxiv.org/abs/2406.02483)
- Zihan Pan, **Tianchi Liu**, Hardik B. Sailor, Qiongqiong Wang, *Attentive Merging of Hidden Embeddings from Pre-trained Speech Model for Anti-spoofing Detection*, **INTERSPEECH (oral)**, 2024. üîó[[arXiv]](https://arxiv.org/abs/2406.10283)
- ‚≠ê**Tianchi Liu**, Kong Aik Lee, Qiongqiong Wang, Haizhou Li, *Golden Gemini is All You Need: Finding the Sweet Spots for Speaker Verification*, IEEE/ACM Transactions on Audio, Speech, and Language Processing **(TASLP)**, 2024. üîó[\[IEEE Open Access](https://ieeexplore.ieee.org/abstract/document/10497864/), [arXiv](https://arxiv.org/abs/2312.03620), [model](https://github.com/Liu-Tianchi/Golden-Gemini-for-Speaker-Verification), [code\]](https://github.com/wenet-e2e/wespeaker/tree/master/examples/voxceleb/v2)
- Ruijie Tao, Zhan Shi, Yidi Jiang, **Tianchi Liu**, Haizhou Li, *Voice Conversion Augmentation for Speaker Recognition on Defective Datasets*, 2024. üîó[[arXiv]](https://arxiv.org/abs/2404.00863)

**2023**
- ‚≠ê**Tianchi Liu**, Kong Aik Lee, Qiongqiong Wang, Haizhou Li, *Disentangling Voice and Content with Self-Supervision for Speaker Recognition*, Advances in Neural Information Processing Systems (**NeurIPS**), 2023. üîó[\[NeurIPS](https://proceedings.neurips.cc/paper_files/paper/2023/hash/9d276b0a087efdd2404f3295b26c24c1-Abstract-Conference.html), [arXiv\]](https://arxiv.org/abs/2310.01128)
- Qiongqiong Wang, Kong Aik Lee, **Tianchi Liu**, *Incorporating Uncertainty from Speaker Embedding Estimation to Speaker Verification*, IEEE International Conference on Acoustics, Speech and Signal Processing (**ICASSP**) **oral**, 2023. üîó[\[IEEE](https://ieeexplore.ieee.org/document/10097019/), [arXiv\]](https://arxiv.org/abs/2302.11763)

**2022**
- ‚≠ê**Tianchi Liu**, Rohan Kumar Das, Kong Aik Lee, Haizhou Li, *MFA: TDNN with multi-scale frequency-channel attention for text-independent speaker verification with short utterances*, IEEE International Conference on Acoustics, Speech and Signal Processing (**ICASSP**) **oral**, 2022. üîó[\[IEEE](https://ieeexplore.ieee.org/abstract/document/9747021/), [arXiv](https://arxiv.org/abs/2202.01624), [code\]](https://github.com/Liu-Tianchi/MFA-TDNN)
- **Tianchi Liu**, Rohan Kumar Das, Kong Aik Lee, Haizhou Li, *Neural acoustic-phonetic approach for speaker verification with phonetic attention mask*, IEEE Signal Processing Letters (**SPL**), 2022. üîó[[IEEE Open Access]](https://ieeexplore.ieee.org/abstract/document/9681187/)
- Qiongqiong Wang, Kong Aik Lee, **Tianchi Liu**, *Scoring of Large-Margin Embeddings for Speaker Verification: Cosine or PLDA?*, **INTERSPEECH (oral)**, 2022. üîó[\[ISCA](https://www.isca-archive.org/interspeech_2022/wang22r_interspeech.html), [arXiv\]](https://arxiv.org/abs/2204.03965)

**2019 - 2020** 

- **Tianchi Liu**, Rohan Kumar Das, Maulik Madhavi, Shengmei Shen, Haizhou Li, *Speaker-Utterance Dual Attention for Speaker and Utterance Verification*, **INTERSPEECH**, 2020. üîó[\[ISCA](https://www.isca-archive.org/interspeech_2020/liu20u_interspeech.html), [arXiv\]](https://arxiv.org/abs/2008.08901)
- **Tianchi Liu**, Maulik C Madhavi, Rohan Kumar Das, Haizhou Li, *A Unified Framework for Speaker and Utterance Verification*, **INTERSPEECH**, 2019. üîó[\[ISCA](https://www.isca-archive.org/interspeech_2019/liu19m_interspeech.html), [code\]](https://github.com/Liu-Tianchi/SUV)

# üíª Open Source Contributions
- *WeSpeaker* [![](https://img.shields.io/github/stars/TaoRuijie/ECAPATDNN?style=social&label=ECAPA-TDNN)](https://github.com/wenet-e2e/wespeaker)

# üéñ Others

**Award**

- Nanyang Speech Technology Forum, Best Student Paper Award, 2023
- The 5nd place winner in NIST Speaker Recognition Evaluation (SRE), 2021
- The 4rd place winner in the ActivityNet Challenge (Speaker), CVPR Workshop, 2021
- NUS Research Scholarship, 2019

**Reviewer**

- IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP),
- IEEE Signal Processing Letters (SPL),
- INTERSPEECH
